{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "onbjBdnoELH1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the names\n",
        "names = [name.strip() for name in open(\"names.txt\")]"
      ],
      "metadata": {
        "id": "N4BygUVaEUv6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process characters\n",
        "chars = [\".\"] + sorted(list(set(\"\".join(names))))\n",
        "stoi = {chars[i]: i for i in range(len(chars))}\n",
        "itos = {v: k for k, v in stoi.items()}"
      ],
      "metadata": {
        "id": "CL1nhyUaEXAn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset for trigram model\n",
        "xs = []\n",
        "ys = []\n",
        "for name in names:\n",
        "    chars = [\".\"] + list(name) + [\".\"]\n",
        "    for ch1, ch2, ch3 in zip(chars, chars[1:], chars[2:]):\n",
        "        xs.append([stoi[ch1], stoi[ch2]])\n",
        "        ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "mZNbhEKGEZnq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_length = len(stoi)"
      ],
      "metadata": {
        "id": "8nER1t7REcn2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the inputs\n",
        "x1 = F.one_hot(xs[:, 0], num_classes=input_length).float()\n",
        "x2 = F.one_hot(xs[:, 1], num_classes=input_length).float()\n",
        "xn = torch.cat([x1, x2], dim=1)"
      ],
      "metadata": {
        "id": "lp7TNXgPEe-x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "w = torch.randn((2 * input_length, input_length), generator=g, requires_grad=True)\n",
        "\n",
        "# Training parameters\n",
        "num_samples = len(xs)\n",
        "lr = 50"
      ],
      "metadata": {
        "id": "wycelPqoEhgh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for i in range(200):\n",
        "    # Forward pass\n",
        "    logits = xn @ w\n",
        "    exp = torch.exp(logits)\n",
        "    softmax = exp / exp.sum(dim=1, keepdim=True)\n",
        "\n",
        "    # Loss calculation\n",
        "    loss = -torch.log(softmax[range(num_samples), ys]).mean()\n",
        "\n",
        "    # Backward pass\n",
        "    w.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient descent update\n",
        "    with torch.no_grad():\n",
        "        w -= lr * w.grad\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ailIQujMEkg5",
        "outputId": "b92009e7-d609-4bd9-f512-aa0fbf5d4305"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2465996742248535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new names\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "for _ in range(10):\n",
        "    ix1, ix2 = 0, 0\n",
        "    output = []\n",
        "    while True:\n",
        "        xenc = torch.cat([F.one_hot(torch.tensor(ix1), num_classes=input_length).float(),\n",
        "                          F.one_hot(torch.tensor(ix2), num_classes=input_length).float()])\n",
        "        logits = xenc @ w\n",
        "        exp = torch.exp(logits)\n",
        "        softmax = exp / exp.sum(dim=0, keepdim=True)\n",
        "        ix = torch.multinomial(softmax, num_samples=1, replacement=True, generator=g).item()\n",
        "        if ix == 0:\n",
        "            break\n",
        "        output.append(itos[ix])\n",
        "        ix1, ix2 = ix2, ix\n",
        "    print(\"\".join(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1Ld9fxdErtL",
        "outputId": "2696129a-e48d-4a07-e53d-c93f000a3147"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aunide\n",
            "aliasad\n",
            "ushfay\n",
            "ainn\n",
            "aui\n",
            "ritoleras\n",
            "get\n",
            "adannaa\n",
            "zabileniassibdainrwi\n",
            "ol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dHgwPrNE7rJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}